<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>  
    div.padded {  
      padding-top: 0px;  
      padding-right: 100px;  
      padding-bottom: 0.25in;  
      padding-left: 100px;  
    }  
  </style> 
<title>Bronya Yang and Carl Gan  |  CS 184</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="style.css" media="screen" />
</head>
<body>
<br />
<h1 align="middle">Assignment 3: PathTracer</h1>
    <h2 align="middle">Bronya Yang and Carl Gan</h2>

    <div class="padded">
        <p>In this assignment, we implement the path tracer. First, we generate ray in the world space and test for intersection.
        Then, since there are a lot of primitives in the world, we speed up the intersection test by using bounding volume hierarchy.
        We found that checking the intersection for bounding box to be the most difficult. We also implement direct lighting to give objects pretty shading.
        In addition to this, we implement indirect lighting to give the most realistic render. In the end, we do adaptive sampling to
        remove the noise in the picture.</p>

    <h2 align="middle">Part 1: Ray Generation and Intersection</h2>
        <p>For ray generation, we first convert the input coordinates from image space to camera space by using these transformation:</p>
            <p align="middle"><pre align="middle">x_cam = (x_image-0.5)*2*tan(radians(hFov)/2)</pre></p>
            <p align="middle"><pre align="middle">y_cam = (y_image-0.5)*2*tan(radians(vFov)/2)</pre></p>
            <p>Then, we generate ray in camera space with origin (0, 0, 0) and direction (x_cam, y_cam, -1) normalized.
            To convert this ray to world space, we add camera position to the origin and do a camera to world rotation on the direction vector.
            In the end, min_t of the ray is set to nClip and max_t is set to fClip.</p>

            <p>Within the unit square between (x_image, y_image) and (x_image+1, y_image+1), we randomly generate coordinates and convert to rays in the world space.
            The number of rays generated is determined by the number of samples wanted. For each ray, we call est_radiance_global_illumination to get the radiance.
            In the end, we perform Monte Carlo by average randiance across samples.</p>

            <p>Next, we implement primitive intersection algorithms. For ray-triangle intersection, we perform Moller Trumbore algorithm.
            and it is a well-known ray-triangle intersection algorithm. Specifically, given ray direction r.d, ray origin, r.o, and triangle vertices p1, p2, p3,
                we follow the below formulas to compute t, b1, b2:</p>

            <p align="middle"><pre align="middle">E1 = p2-p1</pre></p>
            <p align="middle"><pre align="middle">E2 = p3-p1</pre></p>
            <p align="middle"><pre align="middle">S = r.o-p1</pre></p>
            <p align="middle"><pre align="middle">S1 = cross(r.d, E2)</pre></p>
            <p align="middle"><pre align="middle">S2 = cross(S, E1)</pre></p>
            <p align="middle"><pre align="middle">t = dot(S2, E2)/dot(S1, E1)</pre></p>
            <p align="middle"><pre align="middle">b1 = dot(S1, S)/dot(S1, E1)</pre></p>
            <p align="middle"><pre align="middle">b2 = dot(S2, r.d)/dot(S1, E1)</pre></p>

            <p>Then, there is a valid intersection if below condition all satisfied:</p>

            <p align="middle"><pre align="middle">b1 >= 0</pre></p>
            <p align="middle"><pre align="middle">b1 <= 1</pre></p>
            <p align="middle"><pre align="middle">b2 >= 0</pre></p>
            <p align="middle"><pre align="middle">b2 <= 1</pre></p>
            <p align="middle"><pre align="middle">(1-b1-b2) >= 0</pre></p>
            <p align="middle"><pre align="middle">(1-b1-b2) <= 1</pre></p>
            <p align="middle"><pre align="middle">t <= r.max_t</pre></p>
            <p align="middle"><pre align="middle">t >= r.min_t</pre></p>
            <p align="middle"><pre align="middle">t >= 0</pre></p>

            <p>In the end, we fill in intersection information. Normal is calculated by barycentric coordinates:</p>
            <p align="middle"><pre align="middle">n =b1 * n2 + b2 * n3 + (1-b1-b2) * n1</pre></p>

            <p>For sphere-ray intersection, we calculate t using below formula:</p>

            <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/sphere.png" width="480px" />
                    <figcaption align="middle">Formula 1.</figcaption>
                </tr>
            </table>
        </div>

            <p>where each variable means the following:</p>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/sphere1.png" width="480px" />
                            <figcaption align="middle">Figure of ray intersecting sphere.</figcaption>
                    </tr>
                </table>
            </div>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/sphere2.png" width="480px" />
                            <figcaption align="middle">Variables.</figcaption>
                    </tr>
                </table>
            </div>

            <p>If b*b-4*a*c is less than 0, there is no intersection. If it is equal to 0, then there is one intersection.
            If it is bigger than 0, there are two intersections. We each if each intersection is within ray min_t and max_t and choose the minimum satisfied t.
            The normal of the intersection is computed by passing in intersection point to sphere normal function.</p>

            <p>The below figures shows images with normal shading for a few small .dae files:</p>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/CBempty.png" width="480px" />
                            <figcaption align="middle">Dae 1 CBempty.</figcaption>
                    </tr>
                </table>
            </div>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/CBspheres.png" width="480px" />
                            <figcaption align="middle">Dae 2 CBspheres.</figcaption>
                    </tr>
                </table>
            </div>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/CBcoil.png" width="480px" />
                            <figcaption align="middle">Dae 3 CBcoil.</figcaption>
                    </tr>
                </table>
            </div>

    <h2 align="middle">Part 2: Bounding Volume Hierarchy</h2>

        <p>To construct BVH, we first loop through the current primitives, record their bounding box centroid to compute average centroid, and count the total primitives.
        After looping through all the primitives, we get the bounding box average centroid, total number of primitives, and a bounding box with all primitives.
        If the number of primitives is less than max_leaf_size, we pass in the bounding box, start and end pointer to the node, and return the node.
            If the number of primitives is larger than max_leaf_size, we choose the longest axis of the current bounding box.
        Then, we take out the bounding box average centroid of the longest axis and split primitives by comparing this value.
        The function for splitting is std::partition. In the end, we recursively call construct BVH on left half and right half after splitting, and set the returning node to node's left and right child, respectively. </p>

            <p>Below figures are a few large .dae files that we can only render with BVH acceleration:</p>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/maxplanck.png" width="480px" />
                            <figcaption align="middle">Dae 1 maxplanck.</figcaption>
                    </tr>
                </table>
            </div>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/CBlucy.png" width="480px" />
                            <figcaption align="middle">Dae 2 CBlucy.</figcaption>
                    </tr>
                </table>
            </div>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/CBdragon.png" width="480px" />
                            <figcaption align="middle">Dae 3 CBdragon.</figcaption>
                    </tr>
                </table>
            </div>


            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/CBbunny.png" width="480px" />
                            <figcaption align="middle">Dae 3 CBbunny.</figcaption>
                    </tr>
                </table>
            </div>

    <p>We render two scenes with moderately complex geometries with and without BVH acceleration. On a local machine
    with 1.4 GHz Quad-Core Intel Core i5, the rendering time for teapot is 7.7372s without BVH acceleration and is 0.0676s with BVH acceleration.
    The rendering time for cow is 19.2345s without BVH acceleration and is 0.0717s with BVH acceleration. We can see that there is significant improvement in rendering speed.
    The reason is that we no longer perform ray-intersection test for each primitive, but only test for leaf's primitives and intermediate bounding boxes which are much fewer tests.</p>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/teapot.png" width="480px" />
                            <figcaption align="middle">Teapot.</figcaption>
                    </tr>
                </table>
            </div>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/cow.png" width="480px" />
                            <figcaption align="middle">Cow.</figcaption>
                    </tr>
                </table>
            </div>

<<<<<<< HEAD
    <h2 align="middle">Part 3: Direct Illumination</h2>
    <p>For uniform hemisphere sampling, we take num_samples samples from hemisphereSampler. Within each iteration, we simply get the sample by calling get_sample(). Then, we initialize a ray using the sample and hit_p, and we also need to make sure that they are in the same coordinate (world). If the ray has an intersection with the scene, we simply aggregate the light emitted at that intersection (will be black if it’s not a light source) scaled by the reciprocal of probability (in uniform hemisphere it’s 2 * PI), the cos_theta, and the reflectance. Then, we divide the result by num_samples to get the averaged result.</p>

    <p>For importance sampling, the basic structure and idea are similar to those of uniform hemisphere sampling, but with some twists. Now, we iterate by the number of lights in the scene.</p>
    <p>Within each iteration, we sample the i-th light from scene:</p>
    <p>If the i-th light is a point light, we simply take one sample from that light. Otherwise, we sample by ns_area_light times.</p>
    <p>Then, we proceed if the direction of the sample is the same as the normal of the surface by checking w_in.z >= 0</p>
    <p>For each light_i, we aggregate L_out by the light_i and scaled by cos_theta, the reflectance, and the reciprocal of the pdf. If the light source is an area light, we also need to divide the aggregation by ns_area_light to get an unbiased result in each iteration.</p>

    <p>Uniform Hemisphere Sampling vs Importance Sampling under the same arguments:</p>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/bunny_1_16_H.png" width="480px" />
                            <figcaption align="middle">Uniform sampling bunny.dae</figcaption>
                    </tr>
                </table>
            </div>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/bunny_1_16.png" width="480px" />
                            <figcaption align="middle">Importance sampling bunny.dae</figcaption>
                    </tr>
                </table>
            </div>

    <p>Increasing the number of light rays with 1 sample per pixel using importance sampling:</p>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/bunny_1_1.png" width="480px" />
                            <figcaption align="middle">Importance sampling bunny.dae with 1 ray</figcaption>
                    </tr>
                </table>
            </div>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/bunny_1_4.png" width="480px" />
                            <figcaption align="middle">Importance sampling bunny.dae with 4 rays</figcaption>
                    </tr>
                </table>
            </div>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/bunny_1_16.png" width="480px" />
                            <figcaption align="middle">Importance sampling bunny.dae with 16 rays</figcaption>
                    </tr>
                </table>
            </div>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/bunny_1_64.png" width="480px" />
                            <figcaption align="middle">Importance sampling bunny.dae with 64 rays</figcaption>
                    </tr>
                </table>
            </div>

    <p>Increasing the number of light rays with 1 sample per pixel using uniform hemisphere sampling:</p>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/bunny_1_1_H.png" width="480px" />
                            <figcaption align="middle">Uniform sampling bunny.dae with 1 ray</figcaption>
                    </tr>
                </table>
            </div>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/bunny_1_4_H.png" width="480px" />
                            <figcaption align="middle">Uniform sampling bunny.dae with 4 rays</figcaption>
                    </tr>
                </table>
            </div>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/bunny_1_16_H.png" width="480px" />
                            <figcaption align="middle">Uniform sampling bunny.dae with 16 rays</figcaption>
                    </tr>
                </table>
            </div>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/bunny_1_64_H.png" width="480px" />
                            <figcaption align="middle">Uniform sampling bunny.dae with 64 rays</figcaption>
                    </tr>
                </table>
            </div>

    <p>We can clearly see that importance sampling creates a less noisy image rendering than a uniform hemisphere sampling under the same conditions, and as we increase the number of light rays per sample, the image gets less noisy, as we reduce the variance in sampling and get a better estimate of the actual amount of light in that pixel.</p>
    


    <h2 align="middle">Part 4: Global Illumination</h2>
    <p>When considering indirect lighting, we first check the if the max_ray_depth is 0 or 1. In the case of 0, we simply return complete darkness - this will altogether generate a zero bounce lighting effect in est_radiance_global_illumination, returning only the light source illuminated, as desired. In the case of 1, we simply return one bounce direct lighting.</p>

    <p>Then, we proceed into the part of recursion. In our implementation, we set the Russian Roulette probability to 0.7, i.e. the recursion continues with a probability %70. The sampling method is also slightly different - this time, we call bsdf->sample_f(…) to get our sampling ray direction and pdf, as well as the BSDF of the current surface. Then, using coin_flip(), we continue with the probability defined above. If we decide to continue, we add the result of another call on at_leat_one_bounce_radiance, scaled by the BSDF of the current surface, the cos_theta, the reciprocal of the pdf, and the reciprocal of the Russian Roulette probability. Now, we have a functioning global illumination as desired.</p>

    <p>Some rendering results using 1024 samples per pixel:</p>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/spheres_1024_4.png" width="480px" />
                    </tr>
                </table>
            </div>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/dragon_1024_4.png" width="480px" />
                    </tr>
                </table>
            </div>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/blob_1024_4.png" width="480px" />
                    </tr>
                </table>
            </div>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/bench_1024_4.png" width="480px" />
                    </tr>
                </table>
            </div>



    <p>For CBbunny.dae, we use 1024 samples per pixel and 0, 1, 2, 3, and 100 max_ray_depth. We can see that 0 returns zero bounce, the light source, 1 returns only one bounce, and 2, 3 start to render some indirect lighting in the shadow. For 100 max depth, the result has much clearer shadows. However, the effect is not significant, since most rays has been terminated by the Russian roulette policy long before reaching the maximum depth.</p>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/bunny_1024_4_depth0.png" width="480px" />
                    </tr>
                </table>
            </div>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/bunny_1024_4_depth1.png" width="480px" />
                    </tr>
                </table>
            </div>

=======
            <h2 align="middle">Part 5: Adaptive Sampling</h2>

        <p>For adaptive sampling, we follow the exact hint in the spec.
            Specifically, we create variable s1 to be the sum of illuminance and s2 to be the sum of square of illuminance over current samples inside raytrace_pixel function.
            Illuminance is calculate by calling .illum() on radiance Vector3D. If the current sample number n is a multiple of samplesPerBatch, we conduct convergence test.
            The convergence test is:</p>
>>>>>>> master
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
<<<<<<< HEAD
                            <img src="images/bunny_1024_4_depth2.png" width="480px" />
                    </tr>
                </table>
            </div>
=======
                            <img src="images/Convergence_test.png" width="480px" />
                            <figcaption align="middle">Convergence test.</figcaption>
                    </tr>
                </table>
            </div>
        <p>where each variable is calculated in the following way:</p>
>>>>>>> master

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
<<<<<<< HEAD
                            <img src="images/bunny_1024_4_depth3.png" width="480px" />
=======
                            <img src="images/I.png" width="480px" />
                            <figcaption align="middle">Calculate I.</figcaption>
>>>>>>> master
                    </tr>
                </table>
            </div>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
<<<<<<< HEAD
                            <img src="images/bunny_1024_4_depth100.png" width="480px" />
=======
                            <img src="images/mean_var.png" width="480px" />
                            <figcaption align="middle">Calculate mean and variance.</figcaption>
>>>>>>> master
                    </tr>
                </table>
            </div>

<<<<<<< HEAD



    <p>For CBbunny.dae, we use 1, 2, 4, 8, 16, 64, and 1024 samples per pixel with 4 light rays. We can clearly see that as we increase the samples per pixel, the rendering becomes much less noisy.</p>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/bunny_1_4_depth4.png" width="480px" />
                    </tr>
                </table>
            </div>
=======
        <p>In the end, if converges before max sample number, we set sampleCountBuffer to be the actual samples used.</p>

        <p>Below figure shows a good sampling rate image and its heat map:</p>
>>>>>>> master

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
<<<<<<< HEAD
                            <img src="images/bunny_2_4_depth4.png" width="480px" />
=======
                            <img src="images/bunny.png" width="480px" />
                            <figcaption align="middle">Bunny with adaptive sampling.</figcaption>
>>>>>>> master
                    </tr>
                </table>
            </div>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
<<<<<<< HEAD
                            <img src="images/bunny_4_4_depth4.png" width="480px" />
=======
                            <img src="images/bunny_rate.png" width="480px" />
                            <figcaption align="middle">Bunny rate with adaptive sampling.</figcaption>
>>>>>>> master
                    </tr>
                </table>
            </div>

<<<<<<< HEAD
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/bunny_8_4_depth4.png" width="480px" />
                    </tr>
                </table>
            </div>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/bunny_16_4_depth4.png" width="480px" />
                    </tr>
                </table>
            </div>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/bunny_64_4_depth4.png" width="480px" />
                    </tr>
                </table>
            </div>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/bunny_1024_4_depth4.png" width="480px" />
                    </tr>
                </table>
            </div>

    <p></p> 


    <h2 align="middle">Part 5: Adaptive Sampling</h2>

    <h2 align="middle">A Few Notes On Webpages</h2>
        <p>Here are a few problems students have encountered in the past. You will probably encounter these problems at some point, so don't wait until right before the deadline to check that everything is working. Test your website on the instructional machines early!</p>
        <ul>
        <li>Your main report page should be called index.html.</li>
        <li>Be sure to include and turn in all of the other files (such as images) that are linked in your report!</li>
        <li>Use only <em>relative</em> paths to files, such as <pre>"./images/image.jpg"</pre>
        Do <em>NOT</em> use absolute paths, such as <pre>"/Users/student/Desktop/image.jpg"</pre></li>
        <li>Pay close attention to your filename extensions. Remember that on UNIX systems (such as the instructional machines), capitalization matters. <pre>.png != .jpeg != .jpg != .JPG</pre>
        <li>Be sure to adjust the permissions on your files so that they are world readable. For more information on this please see this tutorial: <a href="http://www.grymoire.com/Unix/Permissions.html">http://www.grymoire.com/Unix/Permissions.html</a></li>
        <li>And again, test your website on the instructional machines early!</li>
=======


>>>>>>> master
</div>
</body>
</html>




